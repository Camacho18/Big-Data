// 1.
import org.apache.spark.sql.SparkSession

val spark = SparkSession.builder().getOrCreate()

// 2.
val df = spark.read.option("header", "true").option("inferSchema","true")csv("Netflix_2011_2016")

// 3. 
df.columns

// 4.
df.printSchema()

// 5. 
df.head(5)

// 6. 
df.describe().show()

// 7.
val NewDT = df.withColumn("HV Ratio", df("High")+df("Volume"))
NewDT.show()

// 8.
import spark.implicits._
var m: Double = df.filter(max("High"))
df.filter($"High" === max("High")).show()

 df.groupBy(month(df("Date")).alias("Month")).max("High").sortWith(asc("High")).show()


// 9.
// 

// 10. 
 df.select(max("Volume")).show()
 df.select(min("Volume")).show()

// 11. 
 
// A.
df.filter($"Close" < 600).count()

// B.
var CHigh = df.filter($"High" > 500).count()
var count = df.count()
var p: Double = (100*CHigh)/count

// C.
df.select(corr("High","Volume")).show()


// D. 
 df.groupBy(year(df("Date"))).max().show()

// E.
 df.groupBy(month(df("Date")).alias("Month")).avg("Close").sort(asc("Month")).show()
